A block original designed for speaker embedding extraction from my side-project LTCinger
revised a little to compress Attention computation cost (in theory, not tested yet).
compress on K and V, using dual softmax & matmul

This was never tested. I plan to test this in future when I enter NLP or CV, I don't have any data or card to test this yet. 
uploaded now to provide insight